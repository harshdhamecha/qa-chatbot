{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz9+oM+mBgQT+1QY78PmkX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshdhamecha/qa-chatbot/blob/main/Q_A_Bot_AISensy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background\n",
        "\n",
        "This notebook is a demonstration of Q/A Chatbot with Retrieval Augmented Generation. <br>\n",
        "\n",
        "You can download the sample documents from my [GitHub](https://github.com/harshdhamecha/qa-chatbot/tree/main/sample). I have referred 3 AiSensy blogs, and converted them into pdfs.\n"
      ],
      "metadata": {
        "id": "1YkPhPDwZlEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "vnXkqij_Sd1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unnecessary directory if exists\n",
        "\n",
        "!rm -rf /content/sample_data"
      ],
      "metadata": {
        "id": "7FYgMe3jTi9o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Modules"
      ],
      "metadata": {
        "id": "F857voTDZOFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet langchain-pinecone langchain-openai langchain langchain-community pinecone-client tiktoken"
      ],
      "metadata": {
        "id": "YWKB6df1R7VG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured -q\n",
        "!pip install unstructured[local-inference] -q"
      ],
      "metadata": {
        "id": "lNd4X1Io8MqH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API Keys"
      ],
      "metadata": {
        "id": "spIJ8LcjZQ1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OPENAI API Key\\n\")\n",
        "os.environ['PINECONE_API_KEY'] = getpass.getpass(\"Enter Pinecone API Key\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5tPqZ1Z_n2U",
        "outputId": "9c7e5bc7-1a3e-45c7-95e2-13e28ef4356a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OPENAI API Key\n",
            "路路路路路路路路路路\n",
            "Enter Pinecone API Key\n",
            "路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "vLYd8mcRdP0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "def load_documents(path):\n",
        "    loader = DirectoryLoader(path)\n",
        "    documents = loader.load()\n",
        "    return documents"
      ],
      "metadata": {
        "id": "WtGcvmJd_QB2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/'\n",
        "documents = load_documents(directory)"
      ],
      "metadata": {
        "id": "VFKev8_tE6Ni"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "id": "gEjD8A75FOLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93be6434-fa5c-4e82-881b-8f0a3c226650"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "def split_documents(documents, chunk_size=400, chunk_overlap=30):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "qwUj7NiuFR4j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = split_documents(documents)"
      ],
      "metadata": {
        "id": "P0EOaGUtGurn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "6ECP1UvldzqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002')"
      ],
      "metadata": {
        "id": "7iS_m0JkHFAz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Vector Database"
      ],
      "metadata": {
        "id": "0R89Hs59c4Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pc = Pinecone(\n",
        "    api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
        ")\n",
        "\n",
        "index_name = 'qa-langchain'\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,\n",
        "        metric='euclidean',\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-west-2'\n",
        "        )\n",
        "    )\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "7b-50mO3AT2U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "docsearch = PineconeVectorStore.from_documents(chunks, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "u-akA9pUHa8k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_docs(query):\n",
        "    return docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "4svxFRWVHfzf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Design"
      ],
      "metadata": {
        "id": "IHsnHZymcd2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant that provides answers based on the following context: {context}.\\\n",
        "            Response politely and in a humorous way when any off-topic or out-of-context question is being asked.\"\n",
        "        ),\n",
        "        (\"human\", \"{input}\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "OJpTTJAfJ0hi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "KhY38Te5chNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model='gpt-4o')"
      ],
      "metadata": {
        "id": "B6uRyrJPJB1N"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "OgJpqWtuOI9P"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(query, chain):\n",
        "    context = get_similar_docs(query)\n",
        "    response = chain.invoke(\n",
        "        {\n",
        "            \"input\": query,\n",
        "            \"context\": context\n",
        "        }\n",
        "    )\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "40dzblnwNxn9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "yTQhV8JaZby0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the recent update or feature launch by AISensy?\"\n",
        "answer = get_answer(query, chain)"
      ],
      "metadata": {
        "id": "dBjN7PsVOorb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5hgzIPYOxwP",
        "outputId": "3515c8de-c2b4-46b1-8ff9-b96a90e2d33e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you're interested in the latest and greatest! Recently, AiSensy enabled WhatsApp Ticket Booking for the Delhi Transport Corporation (DTC). Now you can book your DTC bus tickets via WhatsApphow convenient is that? If only I could book a vacation through WhatsApp too! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Out-of-context question\n",
        "query = \"How to play cricket?\"\n",
        "answer = get_answer(query, chain)"
      ],
      "metadata": {
        "id": "AzmtPqmKO0Qt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "vs8vLY86PTl_",
        "outputId": "c540b953-a5ac-4403-f3f2-3ed74c68764f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ah, cricket! The glorious game that can turn a sunny afternoon into a thrilling saga. While I'd love to dive into the specifics of googlies and cover drives, I'm here to chat about WhatsApp content marketing strategies. But hey, if you ever need to turn a WhatsApp chat into a cricket discussion, I can help with that! \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noticed How creatively it managed the Out-of-Context Question?"
      ],
      "metadata": {
        "id": "d83rzqiarm6A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWX7DePHPU5A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}